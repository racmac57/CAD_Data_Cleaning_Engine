Assist Own Agency (Backup)\\n\\n[5 rows x 7 columns]\\n\\nFound 7 incident columns: ['Incident_2019', 'Incident_2020', 'Incident_2021', 'Incident_2022', 'Incident_2023', 'Incident_2024', 'Incident_2025']\\nNumber of unique incidents across all years: 654\\n\\nTop 10 most common incidents:\\n  - Blocked Driveway: 7 occurrences\\n  - Meal Break: 7 occurrences\\n  - Assist Own Agency (Backup): 7 occurrences\\n  - Task Assignment: 7 occurrences\\n  - Dispute: 7 occurrences\\n  - Relief / Personal: 7 occurrences\\n  - Hazard All Other: 7 occurrences\\n  - Alarm - Burglar: 7 occurrences\\n  - Welfare Check: 7 occurrences\\n  - Administrative Assignment: 7 occurrences\\n\\nSaved unique incidents to unique_incidents.csv\\n\",\"stderr\":\"\"}",
            "uuid": "b2bd90bc-d1f4-4456-97b3-c701b9bdfb22"
          }
        ],
        "is_error": false,
        "display_content": {
          "type": "json_block",
          "json_block": "{\"returncode\":0,\"stdout\":\"Columns: ['Incident_2019', 'Incident_2020', 'Incident_2021', 'Incident_2022', 'Incident_2023', 'Incident_2024', 'Incident_2025']\\nNumber of rows: 386\\n\\nSample data (first 5 rows):\\n          Incident_2019  ...               Incident_2025\\n0      Blocked Driveway  ... Emergency Access Card Use\\n1            Meal Break  ...                Patrol Check\\n2         Medical Call   ... Blocked Driveway\\n3      Noise Complaint   ... Unwanted Person\\n4  Suspicious Incident   ... Assist Own Agency (Backup)\\n\\n[5 rows x 7 columns]\\n\\nFound 7 incident columns: ['Incident_2019', 'Incident_2020', 'Incident_2021', 'Incident_2022', 'Incident_2023', 'Incident_2024', 'Incident_2025']\\nNumber of unique incidents across all years: 654\\n\\nTop 10 most common incidents:\\n  - Blocked Driveway: 7 occurrences\\n  - Meal Break: 7 occurrences\\n  - Assist Own Agency (Backup): 7 occurrences\\n  - Task Assignment: 7 occurrences\\n  - Dispute: 7 occurrences\\n  - Relief / Personal: 7 occurrences\\n  - Hazard All Other: 7 occurrences\\n  - Alarm - Burglar: 7 occurrences\\n  - Welfare Check: 7 occurrences\\n  - Administrative Assignment: 7 occurrences\\n\\nSaved unique incidents to unique_incidents.csv\\n\",\"stderr\":\"\"}"
        }
      },
      {
        "start_timestamp": "2025-11-14T02:54:55.379753+00:00",
        "stop_timestamp": "2025-11-14T02:54:55.618047+00:00",
        "type": "text",
        "text": "\n\nNow let's look at the existing clean file structure:",
        "citations": []
      },
      {
        "start_timestamp": "2025-11-14T02:54:55.879268+00:00",
        "stop_timestamp": "2025-11-14T02:55:17.666374+00:00",
        "type": "tool_use",
        "name": "create_file",
        "input": {
          "path": "/home/claude/work/analyze_clean_data.py",
          "file_text": "import pandas as pd\nimport re\n\n# Paths\nCLEAN_FILE_PATH = '/mnt/user-data/uploads/CallType_Categories_clean.xlsx'\n\n# Load clean file\nclean_df = pd.read_excel(CLEAN_FILE_PATH)\nprint(f\"Columns in clean file: {list(clean_df.columns)}\")\nprint(f\"Number of rows: {len(clean_df)}\")\n\n# Identify all columns with Response in their name\nresponse_cols = [col for col in clean_df.columns if 'Response' in col]\nif response_cols:\n    print(f\"\\nResponse columns: {response_cols}\")\n    for col in response_cols:\n        unique_vals = clean_df[col].dropna().unique()\n        print(f\"Unique values in {col}: {sorted(unique_vals)}\")\n\n# Check for title case issues\ndef check_title_case(text):\n    issues = []\n    if pd.isna(text):\n        return issues\n    \n    # Strip statute suffix for this analysis\n    base_text = re.sub(r'\\s*-\\s*((? :2C|39):[0-9A-Za-z.\\-]+)\\s*$', '', str(text))\n    \n    # Check for small words that should be lowercase within a phrase\n    small_words = ['Of', 'And', 'The', 'In', 'On', 'At', 'For', 'To', 'A', 'An', 'Or', 'Nor', 'But']\n    words = base_text.split()\n    \n    # Skip first and last word\n    for i, word in enumerate(words):\n        if i > 0 and i < len(words) - 1:  # Not first or last\n            if word in small_words:\n                issues.append(f\"'{word}' should be lowercase\")\n    \n    # Check for acronyms that should be uppercase\n    acronyms = {'ABC', 'AD', 'ALPR', 'TAS', 'JV', 'A.T.R.A. ', 'A.C.O.R.N. ', 'DV', 'DWI', 'MV', 'MVA', 'EMS', 'DPW', 'DOA', 'CDS', 'UCC', 'CPR', 'AED'}\n    for acronym in acronyms:\n        # Check if present but not in correct case\n        if acronym.lower() in base_text.lower() and not acronym in base_text:\n            issues.append(f\"Acronym '{acronym}' not in correct case\")\n    \n    # Special case for 9-1-1 Emergency\n    if '9-1-1emergency' in base_text.lower() or '9-1-1Emergency' in base_text:\n        issues.append(\"Should be '9-1-1 Emergency'\")\n    \n    return issues\n\n# Check for statute formatting issues\ndef check_statute_format(text):\n    if pd.isna(text):\n        return []\n    \n    issues = []\n    statute_match = re.search(r'\\s*-\\s*((? :2C|39):[0-9A-Za-z.\\-]+)\\s*$', str(text))\n    \n    if statute_match:\n        statute = statute_match.group(1)\n        \n        # Check for proper spacing around hyphen\n        prefix_match = re.search(r'(\\S)-\\s*(? :2C|39)', str(text))\n        if prefix_match:\n            issues.append(\"Missing space before hyphen in statute format\")\n        \n        # Check for spaces within statute part\n        if ' ' in statute:\n            issues.append(\"Spaces in statute part\")\n    \n    return issues\n\n# Apply checks\nclean_df['TitleCaseIssues'] = clean_df['Call Type'].apply(check_title_case)\nclean_df['StatuteIssues'] = clean_df['Call Type'].apply(check_statute_format)\n\n# Identify rows with issues\ntitle_case_issues = clean_df[clean_df['TitleCaseIssues'].apply(lambda x: len(x) > 0)]\nstatute_issues = clean_df[clean_df['StatuteIssues'].apply(lambda x: len(x) > 0)]\n\nprint(f\"\\nFound {len(title_case_issues)} rows with title case issues\")\nprint(f\"Found {len(statute_issues)} rows with statute formatting issues\")\n\n# Show some examples\nif len(title_case_issues) > 0:\n    print(\"\\nSample title case issues:\")\n    for i, row in title_case_issues.head(5).iterrows():\n        print(f\"  - '{row['Call Type']}': {row['TitleCaseIssues']}\")\n\nif len(statute_issues) > 0:\n    print(\"\\nSample statute issues:\")\n    for i, row in statute_issues.head(5).iterrows():\n        print(f\"  - '{row['Call Type']}': {row['StatuteIssues']}\")\n\n# Check for duplicates or near-duplicates\ndef normalize_for_dup_check(text):\n    if pd.isna(text):\n        return ''\n    \n    # Remove all non-alphanumeric chars and convert to lowercase\n    s = re.sub(r'[^a-zA-Z0-9]', '', str(text).lower())\n    return s\n\nclean_df['NormalizedForDupCheck'] = clean_df['Call Type'].apply(normalize_for_dup_check)\ndup_candidates = clean_df['NormalizedForDupCheck'].value_counts()\npotential_dups = dup_candidates[dup_candidates > 1].index.tolist()\n\nprint(f\"\\nFound {len(potential_dups)} normalized values with potential duplicates\")\n\nif potential_dups:\n    print(\"\\nSample potential duplicates:\")\n    for norm_val in potential_dups[:5]:\n        dupes = clean_df[clean_df['NormalizedForDupCheck'] == norm_val]['Call Type'].tolist()\n        print(f\"  - Normalized: '{norm_val}', Variations: {dupes}\")\n",
          "description": "Creating a script to analyze the clean data structure"
        },
        "message": "Creating a script to analyze the clean data structure",
        "display_content": {
          "type": "json_block",
          "json_block": "{\"language\": \"python\", \"code\": \"import pandas as pd\\nimport re\\n\\n# Paths\\nCLEAN_FILE_PATH = '/mnt/user-data/uploads/CallType_Categories_clean.xlsx'\\n\\n# Load clean file\\nclean_df = pd.read_excel(CLEAN_FILE_PATH)\\nprint(f\\\"Columns in clean file: {list(clean_df.columns)}\\\")\\nprint(f\\\"Number of rows: {len(clean_df)}\\\")\\n\\n# Identify all columns with Response in their name\\nresponse_cols = [col for col in clean_df.columns if 'Response' in col]\\nif response_cols:\\n    print(f\\\"\\\\nResponse columns: {response_cols}\\\")\\n    for col in response_cols:\\n        unique_vals = clean_df[col].dropna().unique()\\n        print(f\\\"Unique values in {col}: {sorted(unique_vals)}\\\")\\n\\n# Check for title case issues\\ndef check_title_case(text):\\n    issues = []\\n    if pd.isna(text):\\n        return issues\\n    \\n    # Strip statute suffix for this analysis\\n    base_text = re.sub(r'\\\\s*-\\\\s*((? :2C|39):[0-9A-Za-z.\\\\-]+)\\\\s*$', '', str(text))\\n    \\n    # Check for small words that should be lowercase within a phrase\\n    small_words = ['Of', 'And', 'The', 'In', 'On', 'At', 'For', 'To', 'A', 'An', 'Or', 'Nor', 'But']\\n    words = base_text.split()\\n    \\n    # Skip first and last word\\n    for i, word in enumerate(words):\\n        if i > 0 and i < len(words) - 1:  # Not first or last\\n            if word in small_words:\\n                issues.append(f\\\"'{word}' should be lowercase\\\")\\n    \\n    # Check for acronyms that should be uppercase\\n    acronyms = {'ABC', 'AD', 'ALPR', 'TAS', 'JV', 'A.T.R.A. ', 'A.C.O.R.N. ', 'DV', 'DWI', 'MV', 'MVA', 'EMS', 'DPW', 'DOA', 'CDS', 'UCC', 'CPR', 'AED'}\\n    for acronym in acronyms:\\n        # Check if present but not in correct case\\n        if acronym.lower() in base_text.lower() and not acronym in base_text:\\n            issues.append(f\\\"Acronym '{acronym}' not in correct case\\\")\\n    \\n    # Special case for 9-1-1 Emergency\\n    if '9-1-1emergency' in base_text.lower() or '9-1-1Emergency' in base_text:\\n        issues.append(\\\"Should be '9-1-1 Emergency'\\\")\\n    \\n    return issues\\n\\n# Check for statute formatting issues\\ndef check_statute_format(text):\\n    if pd.isna(text):\\n        return []\\n    \\n    issues = []\\n    statute_match = re.search(r'\\\\s*-\\\\s*((? :2C|39):[0-9A-Za-z.\\\\-]+)\\\\s*$', str(text))\\n    \\n    if statute_match:\\n        statute = statute_match.group(1)\\n        \\n        # Check for proper spacing around hyphen\\n        prefix_match = re.search(r'(\\\\S)-\\\\s*(? :2C|39)', str(text))\\n        if prefix_match:\\n            issues.append(\\\"Missing space before hyphen in statute format\\\")\\n        \\n        # Check for spaces within statute part\\n        if ' ' in statute:\\n            issues.append(\\\"Spaces in statute part\\\")\\n    \\n    return issues\\n\\n# Apply checks\\nclean_df['TitleCaseIssues'] = clean_df['Call Type'].apply(check_title_case)\\nclean_df['StatuteIssues'] = clean_df['Call Type'].apply(check_statute_format)\\n\\n# Identify rows with issues\\ntitle_case_issues = clean_df[clean_df['TitleCaseIssues'].apply(lambda x: len(x) > 0)]\\nstatute_issues = clean_df[clean_df['StatuteIssues'].apply(lambda x: len(x) > 0)]\\n\\nprint(f\\\"\\\\nFound {len(title_case_issues)} rows with title case issues\\\")\\nprint(f\\\"Found {len(statute_issues)} rows with statute formatting issues\\\")\\n\\n# Show some examples\\nif len(title_case_issues) > 0:\\n    print(\\\"\\\\nSample title case issues:\\\")\\n    for i, row in title_case_issues.head(5).iterrows():\\n        print(f\\\"  - '{row['Call Type']}': {row['TitleCaseIssues']}\\\")\\n\\nif len(statute_issues) > 0:\\n    print(\\\"\\\\nSample statute issues:\\\")\\n    for i, row in statute_issues.head(5).iterrows():\\n        print(f\\\"  - '{row['Call Type']}': {row['StatuteIssues']}\\\")\\n\\n# Check for duplicates or near-duplicates\\ndef normalize_for_dup_check(text):\\n    if pd.isna(text):\\n        return ''\\n    \\n    # Remove all non-alphanumeric chars and convert to lowercase\\n    s = re.sub(r'[^a-zA-Z0-9]', '', str(text).lower())\\n    return s\\n\\nclean_df['NormalizedForDupCheck'] = clean_df['Call Type'].apply(normalize_for_dup_check)\\ndup_candidates = clean_df['NormalizedForDupCheck'].value_counts()\\npotential_dups = dup_candidates[dup_candidates > 1].index.tolist()\\n\\nprint(f\\\"\\\\nFound {len(potential_dups)} normalized values with potential duplicates\\\")\\n\\nif potential_dups:\\n    print(\\\"\\\\nSample potential duplicates:\\\")\\n    for norm_val in potential_dups[:5]:\\n        dupes = clean_df[clean_df['NormalizedForDupCheck'] == norm_val]['Call Type'].tolist()\\n        print(f\\\"  - Normalized: '{norm_val}', Variations: {dupes}\\\")\\n\", \"filename\": \"/home/claude/work/analyze_clean_data.py\"}"
        }
      },
      {
        "type": "tool_result",
        "name": "create_file",
        "content": [
          {
            "type": "text",
            "text": "File created successfully: /home/claude/work/analyze_clean_data.py",
            "uuid": "8473248d-659d-4404-b837-34edd2e9492f"
          }
        ],
        "is_error": false,
        "display_content": {
          "type": "text",
          "text": "File created successfully: /home/claude/work/analyze_clean_data.py"
        }
      },
      {
        "start_timestamp": "2025-11-14T02:55:20.684565+00:00",
        "stop_timestamp": "2025-11-14T02:55:21.190502+00:00",
        "type": "tool_use",
        "name": "bash_tool",
        "input": {
          "command": "cd /home/claude/work && python analyze_clean_data.py",
          "description": "Analyzing the clean data for issues"
        },
        "message": "Analyzing the clean data for issues",
        "display_content": {
          "type": "json_block",
          "json_block": "{\"language\": \"bash\", \"code\": \"cd /home/claude/work && python analyze_clean_data.py\"}"
        }
      },
      {
        "type": "tool_result",
        "name": "bash_tool",
        "content": [
          {
            "type": "text",
            "text": "{\"returncode\":0,\"stdout\":\"Columns in clean file: ['Call Type', 'Response', 'Call Type Original']\\nNumber of rows: 525\\n\\nResponse columns: ['Response']\\nUnique values in Response: ['Emergency', 'Routine', 'Urgent']\\n\\nFound 25 rows with title case issues\\nFound 0 rows with statute formatting issues\\n\\nSample title case issues:\\n  - 'ABC Advisory Check': [\\\"Acronym 'AD' not in correct case\\\", \\\"Acronym 'DV' not in correct case\\\"]\\n  - 'Academy Assignment': [\\\"Acronym 'AD' not in correct case\\\"]\\n  - 'Active/Administratively Closed': [\\\"Acronym 'AD' not in correct case\\\"]\\n  - 'Administrative Assignment': [\\\"Acronym 'AD' not in correct case\\\"]\\n  - 'Bad Checks - 2C:21-5': [\\\"Acronym 'AD' not in correct case\\\"]\\n\\nFound 1 normalized values with potential duplicates\\n\\nSample potential duplicates:\\n  - Normalized: 'stabbing', Variations: ['Stabbing', 'Stabbing']\\n\",\"stderr\":\"\"}",
            "uuid": "aca6dba4-df8c-48ea-9bdd-fa4e1b67bdba"
          }
        ],
        "is_error": false,
        "display_content": {
          "type": "json_block",
          "json_block": "{\"returncode\":0,\"stdout\":\"Columns in clean file: ['Call Type', 'Response', 'Call Type Original']\\nNumber of rows: 525\\n\\nResponse columns: ['Response']\\nUnique values in Response: ['Emergency', 'Routine', 'Urgent']\\n\\nFound 25 rows with title case issues\\nFound 0 rows with statute formatting issues\\n\\nSample title case issues:\\n  - 'ABC Advisory Check': [\\\"Acronym 'AD' not in correct case\\\", \\\"Acronym 'DV' not in correct case\\\"]\\n  - 'Academy Assignment': [\\\"Acronym 'AD' not in correct case\\\"]\\n  - 'Active/Administratively Closed': [\\\"Acronym 'AD' not in correct case\\\"]\\n  - 'Administrative Assignment': [\\\"Acronym 'AD' not in correct case\\\"]\\n  - 'Bad Checks - 2C:21-5': [\\\"Acronym 'AD' not in correct case\\\"]\\n\\nFound 1 normalized values with potential duplicates\\n\\nSample potential duplicates:\\n  - Normalized: 'stabbing', Variations: ['Stabbing', 'Stabbing']\\n\",\"stderr\":\"\"}"
        }
      },
      {
        "start_timestamp": "2025-11-14T02:55:24.142173+00:00",
        "stop_timestamp": "2025-11-14T02:55:24.602493+00:00",
        "type": "text",
        "text": "\n\nNow let's load the unique incidents from historical data and compare with the clean file:",
        "citations": []
      },
      {
        "start_timestamp": "2025-11-14T02:55:24.964773+00:00",
        "stop_timestamp": "2025-11-14T02:56:21.848938+00:00",
        "type": "tool_use",
        "name": "create_file",
        "input": {
          "path": "/home/claude/work/build_master_mapping.py",
          "file_text": "import pandas as pd\nimport re\nimport csv\nfrom pathlib import Path\nfrom collections import defaultdict\n\n# Paths\nCLEAN_FILE_PATH = '/mnt/user-data/uploads/CallType_Categories_clean.xlsx'\nHISTORICAL_DATA_PATH = '/mnt/user-data/uploads/2019_2025_10_Call_Types_Incidents_csv.txt'\nOUTPUT_DIR = Path('/home/claude/work')\n\n# Small words to keep lowercase\nSMALL_WORDS = {'a', 'an', 'and', 'as', 'at', 'but', 'by', 'for', 'if', 'in', \n                'of', 'on', 'or', 'the', 'to', 'with', 'nor'}\n\n# Acronyms to preserve\nACRONYMS = {'ABC', 'AD', 'ALPR', 'TAS', 'JV', 'A.T.R.A. ', 'A.C.O.R.N. ', 'DV', 'DWI', \n            'MV', 'MVA', 'EMS', 'DPW', 'DOA', 'CDS', 'UCC', 'CPR', 'AED'}\n\n# Pattern for statute suffixes\nSTATUTE_SUFFIX_RE = re.compile(\n    r\"\\s*-\\s*((? :2C|39):[0-9A-Za-z.\\-]+)\\s*$\"\n)\n\ndef smart_title_case(text):\n    \"\"\"Apply smart title case with preservation of acronyms and small words.\"\"\"\n    if not text:\n        return \"\"\n    \n    # Special case for 9-1-1 Emergency\n    text = re.sub(r'9-1-1[eE]mergency', '9-1-1 Emergency', text)\n    \n    # Split text into words\n    words = text.split()\n    result = []\n    \n    # Process each word\n    for i, word in enumerate(words):\n        # Check if it's an acronym (full match)\n        if word.upper() in ACRONYMS:\n            result.append(word.upper())\n        # Check for acronym parts (partial match)\n        elif any(acronym in word.upper() for acronym in ACRONYMS):\n            # This is a complex case, handle it specifically\n            for acronym in ACRONYMS:\n                if acronym in word.upper():\n                    word = word.replace(word.upper().replace(acronym, ''), \n                                       word.upper().replace(acronym, '').lower())\n                    word = word.replace(acronym.upper(), acronym)\n            result.append(word)\n        # First word or after a colon always capitalized\n        elif i == 0 or (i > 0 and words[i-1].endswith(':')):\n            result.append(word.capitalize())\n        # Small words in the middle stay lowercase\n        elif word.lower() in SMALL_WORDS and i != 0 and i != len(words) - 1:\n            result.append(word.lower())\n        # Other words get capitalized\n        else:\n            result.append(word.capitalize())\n    \n    return ' '.join(result)\n\ndef extract_statute(text):\n    \"\"\"Extract statute information from call type.\"\"\"\n    if not text:\n        return None, None\n    \n    m = STATUTE_SUFFIX_RE.search(text)\n    if not m:\n        return None, None\n    \n    statute_text = m.group(1)\n    statute_type = statute_text.split(':')[0] if ':' in statute_text else None\n    \n    return statute_type, statute_text\n\ndef clean_call_type(value):\n    \"\"\"Apply all normalization rules to a call type.\"\"\"\n    if pd.isna(value):\n        return \"\"\n\n    s = str(value)\n\n    # Trim and collapse internal whitespace\n    s = s.strip()\n    s = re.sub(r\"\\s+\", \" \", s)\n\n    # Replace em dash, en dash and non-breaking spaces\n    s = s.replace(\"\\u2014\", \"-\").replace(\"\\u2013\", \"-\").replace(\"\\u00A0\", \" \")\n    \n    # Remove other hidden Unicode characters\n    s = ''.join(c for c in s if ord(c) < 128 or c.isalpha())\n\n    # Try to find a statute suffix\n    m = STATUTE_SUFFIX_RE.search(s)\n    if not m:\n        # No \" - 2C\" or \" - 39\" style suffix\n        return smart_title_case(s)\n\n    # Text before the suffix\n    base_text = s[: m.start()]\n    base_text = base_text.rstrip(\" -\")\n    base_text = smart_title_case(base_text)\n\n    # Statute part with spaces removed\n    statute = m.group(1).replace(\" \", \"\")\n\n    # Final normalized form\n    return f\"{base_text} - {statute}\"\n\ndef normalize_for_dup_check(text):\n    \"\"\"Normalize text for duplicate detection.\"\"\"\n    if pd.isna(text):\n        return ''\n    \n    # Remove all non-alphanumeric chars and convert to lowercase\n    s = re.sub(r'[^a-zA-Z0-9]', '', str(text).lower())\n    return s\n\ndef load_historical_incidents():\n    \"\"\"Load and process historical incident data.\"\"\"\n    try:\n        # Read as tab-delimited\n        hist_df = pd.read_csv(HISTORICAL_DATA_PATH, sep='\\t', encoding='latin1')\n        \n        # Collect all incidents across years\n        all_incidents = []\n        incident_counts = defaultdict(int)\n        \n        incident_cols = [col for col in hist_df.columns if col.startswith('Incident_')]\n        for col in incident_cols:\n            for incident in hist_df[col].dropna():\n                all_incidents.append(incident)\n                incident_counts[incident] += 1\n        \n        return all_incidents, incident_counts\n    \n    except Exception as e:\n        print(f\"Error loading historical data: {e}\")\n        return [], defaultdict(int)\n\ndef create_master_mapping():\n    \"\"\"Create the master mapping from all sources.\"\"\"\n    # Load clean file (baseline)\n    clean_df = pd.read_excel(CLEAN_FILE_PATH)\n    \n    # Load historical incidents\n    hist_incidents, hist_counts = load_historical_incidents()\n    \n    # Create mapping dataframe\n    mapping_rows = []\n    \n    # Track which raw values are already mapped\n    mapped_raw_values = set()\n    \n    # Process current clean types first\n    for _, row in clean_df.iterrows():\n        raw_value = row['Call Type Original'] if 'Call Type Original' in clean_df.columns else row['Call Type']\n        normalized = clean_call_type(row['Call Type'])\n        \n        # Extract statute info\n        statute_type, statute = extract_statute(normalized)\n        \n        mapping_rows.append({\n            'Raw_Value': raw_value,\n            'Incident_Norm': normalized,\n            'Category_Type': '',  # Not available in current data\n            'Response_Type': row.get('Response', ''),\n            'Statute': statute_type if statute_type else '',\n            'Source': 'Current CAD',\n            'Status': 'Approved',\n            'Note': ''\n        })\n        \n        mapped_raw_values.add(raw_value)\n    \n    # Process historical incidents that aren't already mapped\n    for raw_incident in hist_incidents:\n        if raw_incident not in mapped_raw_values:\n            normalized = clean_call_type(raw_incident)\n            \n            # Extract statute info\n            statute_type, statute = extract_statute(normalized)\n            \n            mapping_rows.append({\n                'Raw_Value': raw_incident,\n                'Incident_Norm': normalized,\n                'Category_Type': '',\n                'Response_Type': '',\n                'Statute': statute_type if statute_type else '',\n                'Source': 'Historical CAD',\n                'Status': 'Needs Review',\n                'Note': f\"Count in historical data: {hist_counts[raw_incident]}\"\n            })\n            \n            mapped_raw_values.add(raw_incident)\n    \n    # Create dataframe\n    mapping_df = pd.DataFrame(mapping_rows)\n    \n    # Sort by source (Current CAD first) then by normalized value\n    mapping_df = mapping_df.sort_values(['Source', 'Incident_Norm'], ascending=[False, True])\n    \n    return mapping_df, hist_counts\n\ndef identify_duplicates(mapping_df):\n    \"\"\"Identify potential duplicates in the mapping.\"\"\"\n    # Add normalized column for duplicate detection\n    mapping_df['Normalized'] = mapping_df['Incident_Norm'].apply(normalize_for_dup_check)\n    \n    # Find duplicates\n    dup_norm_values = mapping_df['Normalized'].value_counts()\n    potential_dups = dup_norm_values[dup_norm_values > 1].index.tolist()\n    \n    # Create duplicates review dataframe\n    dup_rows = []\n    \n    for norm_val in potential_dups:\n        dupes = mapping_df[mapping_df['Normalized'] == norm_val]\n        \n        # Group by current normalized values\n        for norm_incident, group in dupes.groupby('Incident_Norm'):\n            raw_values = group['Raw_Value'].tolist()\n            sources = group['Source'].tolist()\n            \n            dup_rows.append({\n                'Normalized_Group': norm_val,\n                'Current_Incident_Norm': norm_incident,\n                'Raw_Values': '; '.join(raw_values),\n                'Sources': '; '.join(sources),\n                'Suggested_Keeper': norm_incident,\n                'Action': 'Review'\n            })\n    \n    return pd.DataFrame(dup_rows)\n\ndef identify_anomalies(mapping_df):\n    \"\"\"Identify anomalies in the normalized values.\"\"\"\n    anomaly_rows = []\n    \n    for _, row in mapping_df.iterrows():\n        issues = []\n        \n        # Check title case issues\n        incident_norm = row['Incident_Norm']\n        \n        # Skip statute part for these checks\n        base_text = re.sub(r'\\s*-\\s*((? :2C|39):[0-9A-Za-z.\\-]+)\\s*$', '', incident_norm)\n        \n        # Check for small words that should be lowercase\n        words = base_text.split()\n        for i, word in enumerate(words):\n            if i > 0 and i < len(words) - 1:  # Not first or last\n                if word.lower() in SMALL_WORDS and word != word.lower():\n                    issues.append(f\"'{word}' should be lowercase\")\n        \n        # Check for acronyms\n        for acronym in ACRONYMS:\n            if acronym.lower() in base_text.lower() and acronym not in base_text:\n                if acronym.upper() in base_text.upper():  # It exists but in wrong case\n                    issues.append(f\"Acronym '{acronym}' not in correct case\")\n        \n        # Special case for 9-1-1 Emergency\n        if '9-1-1emergency' in base_text.lower() or '9-1-1Emergency' in base_text:\n            issues.append(\"Should be '9-1-1 Emergency'\")\n        \n        # Check statute formatting\n        statute_match = re.search(r'\\s*-\\s*((? :2C|39):[0-9A-Za-z.\\-]+)\\s*$', incident_norm)\n        if statute_match:\n            statute = statute_match.group(1)\n            \n            # Check for proper spacing around hyphen\n            prefix_match = re.search(r'(\\S)-\\s*(?