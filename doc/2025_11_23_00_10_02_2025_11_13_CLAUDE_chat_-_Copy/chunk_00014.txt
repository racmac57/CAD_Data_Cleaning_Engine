Copy the script to the appropriate location:\n   ```bash\n   # If you want it in the main directory\n   cp /path/to/cad_data_enricher.py .\n   \n   # Or if you want it in a scripts subdirectory\n   mkdir -p scripts\n   cp /path/to/cad_data_enricher.py scripts/\n   ```\n\n4. Place your input files in the appropriate directories:\n   - Put your cleaned CAD export in `data/processed/`\n   - Put your CallType_Categories.xlsx in `data/reference/`\n\n5. Run the script:\n   ```bash\n   # If the script is in the main directory\n   python cad_data_enricher.py --cad-file data/processed/your_cleaned_cad.csv --reference-file data/reference/CallType_Categories.xlsx --output data/enriched/CAD_Master_Merged.csv\n   \n   # If the script is in the scripts directory\n   python scripts/cad_data_enricher.py --cad-file data/processed/your_cleaned_cad.csv --reference-file data/reference/CallType_Categories.xlsx --output data/enriched/CAD_Master_Merged.csv\n   ```\n\n## Integration with Other Scripts\n\nIf you have other scripts in your cleaning engine pipeline, you can import and use the functions from `cad_data_enricher.py`:\n\n1. Create a main script that coordinates your entire pipeline, for example `main.py`:\n\n```python\n#!/usr/bin/env python3\n# CAD_Data_Cleaning_Engine/main.py\n# Author: R. A. Carucci\n# Purpose: Main script for CAD data cleaning and enrichment pipeline\n\nimport os\nimport logging\nfrom pathlib import Path\n\n# Import from your other scripts\nfrom scripts.cad_data_cleaner import clean_data  # Assuming you have this function\nfrom scripts.cad_data_enricher import load_data, merge_cad_with_reference, save_data\n\n# Set up logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\ndef main():\n    # Define paths\n    data_dir = Path(\"data\")\n    raw_dir = data_dir / \"raw\"\n    processed_dir = data_dir / \"processed\"\n    reference_dir = data_dir / \"reference\"\n    enriched_dir = data_dir / \"enriched\"\n    \n    # Create directories if they don't exist\n    processed_dir.mkdir(parents=True, exist_ok=True)\n    enriched_dir.mkdir(parents=True, exist_ok=True)\n    \n    # Step 1: Clean raw data (assuming you have this function)\n    raw_file = raw_dir / \"raw_cad_export.csv\"\n    cleaned_file = processed_dir / \"cleaned_cad_export.csv\"\n    if raw_file.exists():\n        logger.info(f\"Cleaning raw data from {raw_file}\")\n        clean_data(raw_file, cleaned_file)\n    else:\n        logger.error(f\"Raw file not found: {raw_file}\")\n        return 1\n    \n    # Step 2: Enrich cleaned data with reference information\n    reference_file = reference_dir / \"CallType_Categories.xlsx\"\n    enriched_file = enriched_dir / \"CAD_Master_Merged.csv\"\n    \n    if cleaned_file.exists() and reference_file.exists():\n        logger.info(f\"Enriching cleaned data with reference information\")\n        \n        # Load data\n        cad_df = load_data(cleaned_file)\n        reference_df = load_data(reference_file)\n        \n        # Merge data\n        merged_df = merge_cad_with_reference(\n            cad_df, \n            reference_df,\n            cad_column='Incident',\n            reference_column='Call Type'\n        )\n        \n        # Save result\n        save_data(merged_df, enriched_file)\n        \n        logger.info(f\"Enriched data saved to {enriched_file}\")\n    else:\n        if not cleaned_file.exists():\n            logger.error(f\"Cleaned file not found: {cleaned_file}\")\n        if not reference_file.exists():\n            logger.error(f\"Reference file not found: {reference_file}\")\n        return 1\n    \n    logger.info(\"CAD data processing pipeline completed successfully\")\n    return 0\n\nif __name__ == \"__main__\":\n    exit(main())\n```\n\n## GitHub Actions Automation (Optional)\n\nIf you want to automate your data processing with GitHub Actions, you could add a workflow file:\n\n1. Create a file `.github/workflows/process_data.yml`:\n\n```yaml\nname: Process CAD Data\n\non:\n  push:\n    paths:\n      - 'data/raw/**'\n      - 'data/reference/**'\n      - 'scripts/**'\n  workflow_dispatch:\n\njobs:\n  process-data:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      \n      - name: Set up Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: '3.9'\n      \n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install pandas openpyxl\n      \n      - name: Run data processing pipeline\n        run: python main.py\n      \n      - name: Commit processed data\n        run: |\n          git config --local user.email \"action@github.com\"\n          git config --local user.name \"GitHub Action\"\n          git add data/processed/ data/enriched/\n          git commit -m \"Update processed data\" || echo \"No changes to commit\"\n          git push\n```\n\nThis will help keep your repository organized and make your data processing workflow repeatable and easy to maintain. ",
        "citations": []
      }
    ],
    "sender": "assistant",
    "index": 9,
    "created_at": "2025-11-14T04:14:09.609273+00:00",
    "updated_at": "2025-11-14T04:14:09.609273+00:00",
    "truncated": false,
    "stop_reason": "stop_sequence",
    "attachments": [],
    "files": [],
    "files_v2": [],
    "sync_sources": [],
    "parent_message_uuid": "019a8091-7b07-7105-9d91-4d23eaf6bda6",
    "nOptions": 1,
    "selectedOption": 0
  }
]