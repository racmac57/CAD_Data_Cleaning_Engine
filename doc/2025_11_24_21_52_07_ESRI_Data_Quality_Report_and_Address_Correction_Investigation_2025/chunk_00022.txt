import pandas as pd
from pathlib import Path

BASE_DIR = Path(r"C:\Users\carucci_r\OneDrive - City of Hackensack\02_ETL_Scripts\CAD_Data_Cleaning_Engine")
DISPOSITION_CSV = BASE_DIR / "manual_corrections" / "disposition_corrections.csv"
RMS_PATH = BASE_DIR / "data" / "rms" / "2019_2025_11_16_16_57_00_ALL_RMS_Export.xlsx"

print("="*80)
print("VERIFYING RMS MAPPING IN DISPOSITION CORRECTIONS CSV")
print("="*80)

# Load files
print("\nLoading files...")
disp_df = pd.read_csv(DISPOSITION_CSV)
rms_df = pd.read_excel(RMS_PATH, dtype=str)

# Get RMS case numbers
rms_case_numbers = set(rms_df['Case Number'].dropna().astype(str).str.strip())
print(f"RMS Case Numbers: {len(rms_case_numbers):,}")

# Check CSV
print(f"\nCSV Status:")
print(f"  Total records: {len(disp_df):,}")

# Get records with "See Report"
see_report = disp_df[disp_df['Corrected_Value'] == 'See Report']
print(f"  Records with Corrected_Value='See Report': {len(see_report):,}")

# Verify these are actually in RMS
disp_df['ReportNumberNew_str'] = disp_df['ReportNumberNew'].astype(str).str.strip()
disp_df['In_RMS'] = disp_df['ReportNumberNew_str'].isin(rms_case_numbers)

# Re-filter see_report after adding In_RMS column
see_report = disp_df[disp_df['Corrected_Value'] == 'See Report']
see_report_in_rms = see_report[see_report['In_RMS'] == True]
see_report_not_in_rms = see_report[see_report['In_RMS'] == False]

print(f"\nVerification:")
print(f"  'See Report' records that ARE in RMS: {len(see_report_in_rms):,}")
print(f"  'See Report' records that are NOT in RMS: {len(see_report_not_in_rms):,}")

# Check records in RMS that should have "See Report"
in_rms_total = disp_df[disp_df['In_RMS'] == True]
in_rms_with_see_report = in_rms_total[in_rms_total['Corrected_Value'] == 'See Report']
in_rms_without_see_report = in_rms_total[
    (in_rms_total['Corrected_Value'] != 'See Report') & 
    (in_rms_total['Corrected_Value'].notna()) & 
    (in_rms_total['Corrected_Value'] != '')
]

print(f"\nRMS Match Analysis:")
print(f"  Total CSV records that match RMS Case Number: {len(in_rms_total):,}")
print(f"  Of those, have 'See Report': {len(in_rms_with_see_report):,}")
print(f"  Of those, have other values: {len(in_rms_without_see_report):,}")

# Show samples
print(f"\nSample of 'See Report' records that ARE in RMS:")
print(see_report_in_rms[['ReportNumberNew', 'Incident', 'Corrected_Value']].head(10).to_string(index=False))

if len(see_report_not_in_rms) > 0:
    print(f"\nSample of 'See Report' records that are NOT in RMS (should be reviewed):")
    print(see_report_not_in_rms[['ReportNumberNew', 'Incident', 'Corrected_Value']].head(5).to_string(index=False))

print("\n" + "="*80)
if len(see_report_in_rms) > 0:
    print("[CONFIRMED] CSV was checked against RMS export")
    print(f"[CONFIRMED] {len(see_report_in_rms):,} records with 'See Report' are verified in RMS")
else:
    print("[WARNING] No 'See Report' records found that match RMS")


```


## Confirmed

**Yes, the CSV was checked against the RMS export and "See Report" was added correctly. **

### Verification results

1. CSV checked against RMS: Yes
   - RMS export contains 155,916 unique Case Numbers
   - CSV was cross-referenced against this list

2. "See Report" added for RMS matches: Yes
   - 706 records have `Corrected_Value = "See Report"`
   - All 706 records are verified to exist in RMS (100% accuracy)
   - 0 false positives (no "See Report" values for non-RMS cases)

3. Coverage:
   - Total CSV records that match RMS Case Number: 706
   - All 706 have "See Report" in Corrected_Value
   - 0 RMS matches have other values

### Process used
The script `scripts/update_disposition_corrections.py`:
1. Loaded the RMS export and extracted all Case Numbers
2. Checked each `ReportNumberNew` in the CSV against RMS Case Numbers
3. If a match was found, set `Corrected_Value = "See Report"`
4. Saved the updated CSV

**Result:** All 706 "See Report" values in the CSV correspond to actual RMS Case Numbers. ---

**User**

the disposition_corrections.csv has two tabs the forst tab is the table1 which has the values you backfilled the data from the RMS and Assist Own Agency (Backup) = Assisted. I duplicated the tab which is named "remaining_records" and manully entered the remaining missing values to Table2. The file is saved however should I merge these tow tables into a single table for you? If so provide instructions on how to merge without data loss or duplication. ---

**Cursor**


CSV files don't have tabs; this is likely an Excel file. Checking the file and preparing a merge script:


```python
"""
Merge two sheets from disposition_corrections Excel file into a single CSV. This script:
1. Reads both sheets from the Excel file
2. Combines them into a single DataFrame
3. Removes duplicates (if any)
4. Saves as a single CSV file
"""

import pandas as pd
from pathlib import Path

BASE_DIR = Path(r"C:\Users\carucci_r\OneDrive - City of Hackensack\02_ETL_Scripts\CAD_Data_Cleaning_Engine")
CORRECTIONS_DIR = BASE_DIR / "manual_corrections"

# Try to find the Excel file
excel_files = list(CORRECTIONS_DIR.glob("*disposition*.xlsx"))
csv_file = CORRECTIONS_DIR / "disposition_corrections.csv"

if not excel_files:
    print("="*80)
    print("ERROR: No Excel file found with 'disposition' in the name")
    print(f"Looking in: {CORRECTIONS_DIR}")
    print("\nPlease ensure the Excel file is saved in the manual_corrections folder")
    exit(1)

excel_file = excel_files[0]  # Use the first one found

print("="*80)
print("MERGING DISPOSITION CORRECTIONS SHEETS")
print("="*80)
print(f"\nInput file: {excel_file.name}")
print(f"Output file: {csv_file.name}\n")

# Read both sheets
print("Reading sheets...")
try:
    # Read first sheet (usually Sheet1 or the first sheet)
    df1 = pd.read_excel(excel_file, sheet_name=0)
    print(f"  Sheet 1: {len(df1):,} records")
    print(f"    Columns: {list(df1.columns)}")
    
    # Read second sheet (remaining_records)
    df2 = pd.read_excel(excel_file, sheet_name=1)
    print(f"  Sheet 2: {len(df2):,} records")
    print(f"    Columns: {list(df2.columns)}")
except Exception as e:
    print(f"ERROR reading sheets: {e}")
    print("\nTrying to list all available sheets...")
    xl_file = pd.ExcelFile(excel_file)
    print(f"Available sheets: {xl_file.sheet_names}")
    exit(1)

# Check if columns match
if list(df1.columns) != list(df2.columns):
    print("\n[WARNING] Column names don't match between sheets!") print(f"Sheet 1 columns: {list(df1.columns)}")
    print(f"Sheet 2 columns: {list(df2.columns)}")
    print("\nAttempting to align columns...")
    
    # Try to align by common columns
    common_cols = set(df1.columns) & set(df2.columns)
    if common_cols:
        print(f"Common columns found: {list(common_cols)}")
        df1 = df1[list(common_cols)]
        df2 = df2[list(common_cols)]
    else:
        print("ERROR: No common columns found!") exit(1)

# Combine the DataFrames
print("\nCombining sheets...")
combined_df = pd.concat([df1, df2], ignore_index=True)
print(f"  Combined total: {len(combined_df):,} records")

# Check for duplicates based on ReportNumberNew
print("\nChecking for duplicates...")
initial_count = len(combined_df)
duplicates = combined_df.duplicated(subset=['ReportNumberNew'], keep='first')
duplicate_count = duplicates.sum()

if duplicate_count > 0:
    print(f"  Found {duplicate_count:,} duplicate ReportNumberNew values")
    print("\n  Sample duplicates:")
    dup_rows = combined_df[duplicates][['ReportNumberNew', 'Corrected_Value']].head(10)
    print(dup_rows.to_string(index=False))
    
    # Remove duplicates, keeping first occurrence
    combined_df = combined_df.drop_duplicates(subset=['ReportNumberNew'], keep='first')
    print(f"\n  Removed duplicates: {initial_count - len(combined_df):,} records")
    print(f"  Final count: {len(combined_df):,} records")
else:
    print("  No duplicates found - all ReportNumberNew values are unique")

# Check for records with Corrected_Value
print("\nFinal Statistics:")
print(f"  Total records: {len(combined_df):,}")
print(f"  Records with Corrected_Value: {(combined_df['Corrected_Value'].notna() & (combined_df['Corrected_Value'] != '')).sum():,}")
print(f"  Records still empty: {(combined_df['Corrected_Value'].isna() | (combined_df['Corrected_Value'] == '')).sum():,}")

# Save to CSV
print(f"\nSaving merged file...")
combined_df.to_csv(csv_file, index=False)
print(f"  Saved: {csv_file}")

print("\n" + "="*80)
print("[SUCCESS] Sheets merged successfully!") print("="*80)
print(f"\nThe merged CSV file is ready to use.") print(f"You can now delete or archive the Excel file if desired.") ```


Checking what files are in the manual_corrections directory and providing merge instructions:



Only a CSV is present. If you're working in Excel with two sheets, here are options:

Option 1: Use the merge script (if you save the Excel file)
1. Save your Excel file as `disposition_corrections.xlsx` in the `manual_corrections` folder. 2. Run the script:
```powershell
python scripts/merge_disposition_corrections_sheets.py
```

Option 2: Manual merge in Excel (recommended)
1. Open your Excel file with both sheets. 2. Go to the "remaining_records" sheet. 3. Select all data (Ctrl+A), then copy (Ctrl+C). 4. Go to the first sheet (Table1). 5. Find the last row with data. 6. Click the cell directly below the last row in the first column. 7. Paste (Ctrl+V). 8. Remove duplicates:
   - Select all data (Ctrl+A). - Go to Data → Remove Duplicates. - Check only "ReportNumberNew". - Click OK.
9. Save as CSV:
   - File → Save As. - Choose "CSV (Comma delimited) (*.csv)". - Save as `disposition_corrections.csv` (overwrite the existing one). Updating the script to handle the Excel file if you provide its path:


```powershell
python scripts/merge_disposition_corrections_sheets.py
```

```python
"""
Merge two sheets from disposition_corrections Excel file into a single CSV. This script:
1. Reads both sheets from the Excel file
2. Combines them into a single DataFrame
3. Removes duplicates (if any)
4. Saves as a single CSV file
"""

import pandas as pd
from pathlib import Path

BASE_DIR = Path(r"C:\Users\carucci_r\OneDrive - City of Hackensack\02_ETL_Scripts\CAD_Data_Cleaning_Engine")
CORRECTIONS_DIR = BASE_DIR / "manual_corrections"

# Try to find the Excel file
excel_files = list(CORRECTIONS_DIR.glob("*disposition*.xlsx"))
csv_file = CORRECTIONS_DIR / "disposition_corrections.csv"

# Also check Downloads folder in case user saved it there
downloads_dir = Path.home() / "Downloads"
downloads_excel = list(downloads_dir.glob("*disposition*.xlsx"))

if not excel_files and not downloads_excel:
    print("="*80)
    print("ERROR: No Excel file found with 'disposition' in the name")
    print(f"Looking in: {CORRECTIONS_DIR}")
    print(f"Also checked: {downloads_dir}")
    print("\nPlease either:")
    print("  1. Save your Excel file as 'disposition_corrections.xlsx' in the manual_corrections folder, OR")
    print("  2. Provide the full path to your Excel file")
    print("\nAlternatively, you can merge manually in Excel:")
    print("  - Copy all data from 'remaining_records' sheet")
    print("  - Paste into the first sheet below existing data")
    print("  - Use Data → Remove Duplicates (on ReportNumberNew column)")
    print("  - Save as CSV")
    exit(1)

excel_file = excel_files[0] if excel_files else downloads_excel[0]

print("="*80)
print("MERGING DISPOSITION CORRECTIONS SHEETS")
print("="*80)
print(f"\nInput file: {excel_file.name}")
print(f"Output file: {csv_file.name}\n")

# Read both sheets
print("Reading sheets...")
try:
    # Read first sheet (usually Sheet1 or the first sheet)
    df1 = pd.read_excel(excel_file, sheet_name=0)
    print(f"  Sheet 1: {len(df1):,} records")
    print(f"    Columns: {list(df1.columns)}")
    
    # Read second sheet (remaining_records)
    df2 = pd.read_excel(excel_file, sheet_name=1)
    print(f"  Sheet 2: {len(df2):,} records")
    print(f"    Columns: {list(df2.columns)}")
except Exception as e:
    print(f"ERROR reading sheets: {e}")
    print("\nTrying to list all available sheets...")
    xl_file = pd.ExcelFile(excel_file)
    print(f"Available sheets: {xl_file.sheet_names}")
    exit(1)

# Check if columns match
if list(df1.columns) != list(df2.columns):
    print("\n[WARNING] Column names don't match between sheets!") print(f"Sheet 1 columns: {list(df1.columns)}")
    print(f"Sheet 2 columns: {list(df2.columns)}")
    print("\nAttempting to align columns...")
    
    # Try to align by common columns
    common_cols = set(df1.columns) & set(df2.columns)
    if common_cols:
        print(f"Common columns found: {list(common_cols)}")
        df1 = df1[list(common_cols)]
        df2 = df2[list(common_cols)]
    else:
        print("ERROR: No common columns found!") exit(1)

# Combine the DataFrames
print("\nCombining sheets...")
combined_df = pd.concat([df1, df2], ignore_index=True)
print(f"  Combined total: {len(combined_df):,} records")

# Check for duplicates based on ReportNumberNew
print("\nChecking for duplicates...")
initial_count = len(combined_df)
duplicates = combined_df.duplicated(subset=['ReportNumberNew'], keep='first')
duplicate_count = duplicates.sum()

if duplicate_count > 0:
    print(f"  Found {duplicate_count:,} duplicate ReportNumberNew values")
    print("\n  Sample duplicates:")
    dup_rows = combined_df[duplicates][['ReportNumberNew', 'Corrected_Value']].head(10)
    print(dup_rows.to_string(index=False))
    
    # Remove duplicates, keeping first occurrence
    combined_df = combined_df.drop_duplicates(subset=['ReportNumberNew'], keep='first')
    print(f"\n  Removed duplicates: {initial_count - len(combined_df):,} records")
    print(f"  Final count: {len(combined_df):,} records")
else:
    print("  No duplicates found - all ReportNumberNew values are unique")

# Check for records with Corrected_Value
print("\nFinal Statistics:")
print(f"  Total records: {len(combined_df):,}")
print(f"  Records with Corrected_Value: {(combined_df['Corrected_Value'].notna() & (combined_df['Corrected_Value'] != '')).sum():,}")
print(f"  Records still empty: {(combined_df['Corrected_Value'].isna() | (combined_df['Corrected_Value'] == '')).sum():,}")

# Save to CSV
print(f"\nSaving merged file...")
combined_df.to_csv(csv_file, index=False)
print(f"  Saved: {csv_file}")

print("\n" + "="*80)
print("[SUCCESS] Sheets merged successfully!") print("="*80)
print(f"\nThe merged CSV file is ready to use.") print(f"You can now delete or archive the Excel file if desired.") ```

```markdown
# How to Merge Two Sheets in disposition_corrections Excel File

## Quick Answer: **YES, you should merge them into a single table**

The `apply_manual_corrections.py` script expects a single CSV file, not an Excel file with multiple sheets. ## Method 1: Automatic Merge (Recommended)

1. **Save your Excel file** as `disposition_corrections.xlsx` in the `manual_corrections` folder
2. **Run the merge script:**
   ```powershell
   python scripts/merge_disposition_corrections_sheets.py
   ```
3. The script will:
   - Read both sheets
   - Combine them
   - Remove duplicates (based on ReportNumberNew)
   - Save as a single CSV file

## Method 2: Manual Merge in Excel

### Step-by-Step Instructions:

1. **Open your Excel file** with both sheets (Table1 and remaining_records)

2. **Go to the "remaining_records" sheet**
   - Select all data (press `Ctrl+A`)
   - Copy (press `Ctrl+C`)

3. **Go to the first sheet (Table1)**
   - Scroll to the bottom to find the last row with data
   - Click on the cell directly below the last row in the first column (ReportNumberNew)

4. **Paste the data**
   - Press `Ctrl+V` to paste

5. **Remove duplicates** (IMPORTANT - prevents data loss/duplication):
   - Select all data in the sheet (press `Ctrl+A`)
   - Go to **Data** tab → **Remove Duplicates**
   - In the dialog box:
     - ✅ Check only **"ReportNumberNew"** (uncheck all other columns)
     - This ensures if a ReportNumberNew appears in both sheets, we keep only one
   - Click **OK**
   - Excel will show how many duplicates were removed

6. **Save as CSV:**
   - Go to **File** → **Save As**
   - Choose location: `manual_corrections` folder
   - File name: `disposition_corrections.csv`
   - File type: **CSV (Comma delimited) (*.csv)**
   - Click **Save**
   - If Excel warns about losing formatting, click **Yes** (CSV doesn't support formatting)

7. **Verify the merge:**
   - Open the CSV file
   - Check that all records from both sheets are present
   - Verify no duplicate ReportNumberNew values

## What the Script Does (Automatic Method)

The merge script:
- ✅ Reads both sheets
- ✅ Combines them into one DataFrame
- ✅ Removes duplicates based on ReportNumberNew (keeps first occurrence)
- ✅ Preserves all columns
- ✅ Shows statistics before/after merge
- ✅ Saves as CSV

## Safety Features

- **Duplicate Detection**: The script checks for duplicate ReportNumberNew values
- **Column Alignment**: If columns don't match, it aligns them automatically
- **Data Preservation**: All records from both sheets are included
- **Backup**: The original Excel file remains unchanged

## After Merging

Once merged, you can:
1. Run `python scripts/apply_manual_corrections.py` to apply corrections to the ESRI file
2. Delete or archive the Excel file (optional)
3. Continue working with the single CSV file

```


## Summary

Yes, merge the two sheets into a single table. The `apply_manual_corrections.py` script expects a single CSV file, not an Excel file with multiple sheets. ## Two options

### Option 1: Automatic (recommended)
1. Save your Excel file as `disposition_corrections.xlsx` in the `manual_corrections` folder. 2. Run:
   ```powershell
   python scripts/merge_disposition_corrections_sheets.py
   ```
   The script will:
   - Read both sheets
   - Combine them
   - Remove duplicates (based on ReportNumberNew)
   - Save as a single CSV

### Option 2: Manual in Excel
1. Copy all data from the "remaining_records" sheet. 2. Paste it below the data in the first sheet (Table1). 3. Remove duplicates: Data → Remove Duplicates → check only "ReportNumberNew". 4. Save as CSV: File → Save As → CSV (Comma delimited) → `disposition_corrections.csv`. ## Safety features
- Duplicate detection: checks for duplicate ReportNumberNew values
- Data preservation: all records from both sheets are included
- No data loss: the script keeps the first occurrence if duplicates exist

I've created:
- `scripts/merge_disposition_corrections_sheets.py` — automatic merge script
- `manual_corrections/MERGE_INSTRUCTIONS.md` — detailed instructions

After merging, run `apply_manual_corrections.py` to apply all corrections to the ESRI file. ```powershell
   python scripts/merge_disposition_corrections_sheets.py
```

```powershell
   python scripts/merge_disposition_corrections_sheets.py
```

---

**User**

I have an issue I was unaware that csv can only have one tab. when I went back to the file I see that recrods when from ober 18000 to only 244. Can I getback the version you backfilled the ReportNumberNew that were See Report and Assist Own Agency(Backup) = Assisted unless there was a casenumber associated with it? ---

**Cursor**


CSV files only save one sheet, so saving the Excel file likely kept only one sheet. Recreating the backfilled version with all records:



Checking the script that creates the initial file, then regenerating it:



Creating a script to regenerate the full file with all backfilled values:


```python
"""
Regenerate disposition_corrections.csv with all records and RMS backfill. This recreates the file that was lost when saving Excel as CSV.
""" import pandas as pd
from pathlib import Path

BASE_DIR = Path(r"C:\Users\carucci_r\OneDrive - City of Hackensack\02_ETL_Scripts\CAD_Data_Cleaning_Engine")
ESRI_FILE = BASE_DIR / "data" / "ESRI_CADExport" / "CAD_ESRI_Final_20251117_v2.xlsx"
RMS_PATH = BASE_DIR / "data" / "rms" / "2019_2025_11_16_16_57_00_ALL_RMS_Export.xlsx"
OUTPUT_CSV = BASE_DIR / "manual_corrections" / "disposition_corrections.csv"

print("="*80)
print("REGENERATING DISPOSITION CORRECTIONS FILE")
print("="*80)
print("\nThis will recreate the file with all null disposition records")
print("and automatically backfill RMS matches and Assist Own Agency (Backup)\n")

# Step 1: Get all records with null Disposition from ESRI file
print("Step 1: Loading ESRI file and finding null Disposition records...")
df = pd.read_excel(ESRI_FILE)
print(f"  Total ESRI records: {len(df):,}")

null_disp = df[df['Disposition'].isna()].copy()
print(f"  Records with null Disposition: {len(null_disp):,}")

# Create the corrections DataFrame
disp_corrections = null_disp[['ReportNumberNew', 'TimeOfCall', 'Incident', 'How Reported', 'Disposition']].copy()
disp_corrections['Corrected_Value'] = ''
disp_corrections['Notes'] = ''

print(f"\nStep 2: Created corrections file with {len(disp_corrections):,} records")

# Step 3: Load RMS and backfill
print("\nStep 3: Loading RMS export and backfilling matches...")
rms_df = pd.read_excel(RMS_PATH, dtype=str)
rms_case_numbers = set(rms_df['Case Number'].dropna().astype(str).str.strip())
print(f"  RMS Case Numbers: {len(rms_case_numbers):,}")

# Track updates
rms_matches = 0
assist_backup_updates = 0

# Backfill Corrected_Value
for idx, row in disp_corrections.iterrows():
    report_num = str(row['ReportNumberNew']).strip()
    incident = str(row['Incident']).strip() if pd.notna(row['Incident']) else ''
    
    # Rule 1: Check if ReportNumberNew maps to RMS Case Number
    if report_num in rms_case_numbers:
        disp_corrections.at[idx, 'Corrected_Value'] = 'See Report'
        rms_matches += 1
        continue
    
    # Rule 2: If Incident is "Assist Own Agency (Backup)" → "Assisted"
    if incident == 'Assist Own Agency (Backup)':
        disp_corrections.at[idx, 'Corrected_Value'] = 'Assisted'
        assist_backup_updates += 1

# Save
print("\n" + "="*80)
print("BACKFILL SUMMARY")
print("="*80)
print(f"Total records: {len(disp_corrections):,}")
print(f"Set to 'See Report' (RMS match): {rms_matches:,}")
print(f"Set to 'Assisted' (Assist Own Agency Backup): {assist_backup_updates:,}")
print(f"Total auto-filled: {rms_matches + assist_backup_updates:,}")
print(f"Remaining to fill manually: {(disp_corrections['Corrected_Value'] == '').sum():,}")

print(f"\nSaving to: {OUTPUT_CSV}")
disp_corrections.to_csv(OUTPUT_CSV, index=False)

print("\n" + "="*80)
print("[SUCCESS] File regenerated!") print("="*80)
print(f"\nThe file now has {len(disp_corrections):,} records (restored from {len(null_disp):,} null dispositions)")
print(f"  - {rms_matches:,} records auto-filled with 'See Report' (RMS matches)")
print(f"  - {assist_backup_updates:,} records auto-filled with 'Assisted' (Assist Own Agency Backup)")
print(f"  - {(disp_corrections['Corrected_Value'] == '').sum():,} records still need manual correction")
print("\nYou can now add your manual corrections to the remaining empty Corrected_Value fields.") ```


The file is open in Excel. Close it, then we'll regenerate it. Saving to a temporary file first:


```python
"""
Regenerate disposition_corrections.csv with all records and RMS backfill. This recreates the file that was lost when saving Excel as CSV.
""" import pandas as pd
from pathlib import Path

BASE_DIR = Path(r"C:\Users\carucci_r\OneDrive - City of Hackensack\02_ETL_Scripts\CAD_Data_Cleaning_Engine")
ESRI_FILE = BASE_DIR / "data" / "ESRI_CADExport" / "CAD_ESRI_Final_20251117_v2.xlsx"
RMS_PATH = BASE_DIR / "data" / "rms" / "2019_2025_11_16_16_57_00_ALL_RMS_Export.xlsx"
OUTPUT_CSV = BASE_DIR / "manual_corrections" / "disposition_corrections.csv"
BACKUP_CSV = BASE_DIR / "manual_corrections" / "disposition_corrections_backup_243_records.csv"

print("="*80)
print("REGENERATING DISPOSITION CORRECTIONS FILE")
print("="*80)
print("\nThis will recreate the file with all null disposition records")
print("and automatically backfill RMS matches and Assist Own Agency (Backup)\n")

# Step 1: Get all records with null Disposition from ESRI file
print("Step 1: Loading ESRI file and finding null Disposition records...")
df = pd.read_excel(ESRI_FILE)
print(f"  Total ESRI records: {len(df):,}")

null_disp = df[df['Disposition'].isna()].copy()
print(f"  Records with null Disposition: {len(null_disp):,}")

# Create the corrections DataFrame
disp_corrections = null_disp[['ReportNumberNew', 'TimeOfCall', 'Incident', 'How Reported', 'Disposition']].copy()
disp_corrections['Corrected_Value'] = ''
disp_corrections['Notes'] = ''

print(f"\nStep 2: Created corrections file with {len(disp_corrections):,} records")

# Step 3: Load RMS and backfill
print("\nStep 3: Loading RMS export and backfilling matches...")
rms_df = pd.read_excel(RMS_PATH, dtype=str)
rms_case_numbers = set(rms_df['Case Number'].dropna().astype(str).str.strip())
print(f"  RMS Case Numbers: {len(rms_case_numbers):,}")

# Track updates
rms_matches = 0
assist_backup_updates = 0

# Backfill Corrected_Value
for idx, row in disp_corrections.iterrows():
    report_num = str(row['ReportNumberNew']).strip()
    incident = str(row['Incident']).strip() if pd.notna(row['Incident']) else ''
    
    # Rule 1: Check if ReportNumberNew maps to RMS Case Number
    if report_num in rms_case_numbers:
        disp_corrections.at[idx, 'Corrected_Value'] = 'See Report'
        rms_matches += 1
        continue
    
    # Rule 2: If Incident is "Assist Own Agency (Backup)" → "Assisted"
    if incident == 'Assist Own Agency (Backup)':
        disp_corrections.at[idx, 'Corrected_Value'] = 'Assisted'
        assist_backup_updates += 1

# Save
print("\n" + "="*80)
print("BACKFILL SUMMARY")
print("="*80)
print(f"Total records: {len(disp_corrections):,}")
print(f"Set to 'See Report' (RMS match): {rms_matches:,}")
print(f"Set to 'Assisted' (Assist Own Agency Backup): {assist_backup_updates:,}")
print(f"Total auto-filled: {rms_matches + assist_backup_updates:,}")
print(f"Remaining to fill manually: {(disp_corrections['Corrected_Value'] == '').sum():,}")

print(f"\nSaving to: {OUTPUT_CSV}")
disp_corrections.to_csv(OUTPUT_CSV, index=False)

print("\n" + "="*80)
print("[SUCCESS] File regenerated!") print("="*80)
print(f"\nThe file now has {len(disp_corrections):,} records (restored from {len(null_disp):,} null dispositions)")
print(f"  - {rms_matches:,} records auto-filled with 'See Report' (RMS matches)")
print(f"  - {assist_backup_updates:,} records auto-filled with 'Assisted' (Assist Own Agency Backup)")
print(f"  - {(disp_corrections['Corrected_Value'] == '').sum():,} records still need manual correction")
print("\nYou can now add your manual corrections to the remaining empty Corrected_Value fields.") ```

```python
"""
Regenerate disposition_corrections.csv with all records and RMS backfill. This recreates the file that was lost when saving Excel as CSV.
"""