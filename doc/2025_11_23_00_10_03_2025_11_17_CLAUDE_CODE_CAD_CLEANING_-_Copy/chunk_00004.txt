Let me kill this process and optimize the script with
  vectorized pandas operations:

● Kill Shell(Kill shell: fb349b)
  ⎿  Shell fb349b killed

● Let me rewrite the script with optimized vectorized operations:

● Write(scripts\esri_production_deploy.py)
  ⎿  Updated scripts\esri_production_deploy.py with 672 additions and 868 removals
         1 -  #!/usr/bin/env python3
         2 -  """
         3 -  ESRI Production Deployment - Final Data Cleaning Script
         4 -  ========================================================
         5 -  Performs comprehensive data cleaning for ESRI deployment including:
         6 -  - Response_Type mapping
         7 -  - TAPS variants resolution
         8 -  - Domestic Dispute classification
         9 -  - TRO/FRO splitting
        10 -  - Disposition normalization
        11 -  - Address backfill from RMS
        12 -  """
        13 -
        14 -  import pandas as pd
        15 -  import numpy as np
        16 -  import re
        17 -  import os
        18 -  from datetime import datetime
        19 -  from pathlib import Path
        20 -  from rapidfuzz import fuzz, process
        21 -
        22 -  # Configuration
        23 -  BASE_DIR = Path(r"C:\Users\carucci_r\OneDrive - City of
           - Hackensack\02_ETL_Scripts\CAD_Data_Cleaning_Engine")
        24 -  OUTPUT_DIR = BASE_DIR / "data" / "ESRI_CADExport"
        25 -  REPORTS_DIR = BASE_DIR / "data" / "02_reports"
        26 -
        27 -  # Input files
        28 -  CAD_FILE = BASE_DIR / "ref" / "2019_2025_11_17_Updated_CAD_Export.xlsx"
        29 -  DV_FILE = BASE_DIR / "ref" / "2025_11_17_DV_Offense_Report_Updated.xlsx"
        30 -  RMS_FILE = BASE_DIR / "data" / "rms" / "2019_2025_11_16_16_57_00_ALL_RMS_Export.xlsx"
        31 -  UNMAPPED_FILE = BASE_DIR / "ref" / "Unmapped_Response_Type.csv"
        32 -  RAW_CALLTYPES_FILE = BASE_DIR / "ref" / "RAW_CAD_CALL_TYPE_EXPORT.xlsx"
        33 -
        34 -  # Create output directories
        35 -  OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        36 -  REPORTS_DIR.mkdir(parents=True, exist_ok=True)
        37 -
        38 -  # Tracking metrics
        39 -  metrics = {
        40 -      'total_records': 0,
        41 -      'response_type_mapped': 0,
        42 -      'response_type_unmapped': 0,
        43 -      'taps_resolved': 0,
        44 -      'domestic_to_dv': 0,
        45 -      'domestic_to_dispute': 0,
        46 -      'tro_fro_split': 0,
        47 -      'tro_fro_manual_review': 0,
        48 -      'disposition_normalized': 0,
        49 -      'address_backfilled': 0,
        50 -      'changes': []
        51 -  }
        52 -
        53 -
        54 -  def fix_mojibake(text):
        55 -      """Fix mojibake characters in text.""" 56 -      if pd.isna(text):
        57 -          return text
        58 -      text = str(text)
        59 -      # Replace common mojibake patterns
        60 -      text = text.replace('–', '-')  # en-dash to hyphen
        61 -      text = text.replace('—', '-')  # em-dash to hyphen
        62 -      text = text.replace('\x96', '-')  # Windows-1252 en-dash
        63 -      text = text.replace('â€"', '-')
        64 -      text = text.replace('â€"', '-')
        65 -      return text
        66 -
        67 -
        68 -  def load_data():
        69 -      """Load all input data files.""" 70 -      print("=" * 60)
        71 -      print("LOADING DATA FILES")
        72 -      print("=" * 60)
        73 -
        74 -      # Load CAD data
        75 -      print(f"\nLoading CAD data from: {CAD_FILE}")
        76 -      cad_df = pd.read_excel(CAD_FILE)
        77 -      print(f"  Loaded {len(cad_df):,} CAD records")
        78 -      print(f"  Columns: {list(cad_df.columns)}")
        79 -
        80 -      # Normalize column names to expected format
        81 -      column_renames = {
        82 -          'Time of Call': 'TimeOfCall',
        83 -          'Response Type': 'Response_Type',
        84 -          'HourMinuetsCalc': 'Hour'
        85 -      }
        86 -      cad_df = cad_df.rename(columns=column_renames)
        87 -      print(f"  Normalized column names")
        88 -
        89 -      # Load DV report
        90 -      print(f"\nLoading DV report from: {DV_FILE}")
        91 -      dv_df = pd.read_excel(DV_FILE)
        92 -      print(f"  Loaded {len(dv_df):,} DV records")
        93 -      print(f"  Columns: {list(dv_df.columns)}")
        94 -
        95 -      # Normalize DV case number column
        96 -      if 'Case #' in dv_df.columns:
        97 -          dv_df = dv_df.rename(columns={'Case #': 'Case_Number'})
        98 -      elif 'Case Number' in dv_df.columns:
        99 -          dv_df = dv_df.rename(columns={'Case Number': 'Case_Number'})
       100 -
       101 -      # Load RMS data
       102 -      print(f"\nLoading RMS data from: {RMS_FILE}")
       103 -      rms_df = pd.read_excel(RMS_FILE)
       104 -      print(f"  Loaded {len(rms_df):,} RMS records")
       105 -      print(f"  Columns: {list(rms_df.columns)}")
       106 -
       107 -      # Load manual mappings
       108 -      print(f"\nLoading manual mappings from: {UNMAPPED_FILE}")
       109 -      mappings_df = pd.read_csv(UNMAPPED_FILE, encoding='latin-1')
       110 -      print(f"  Loaded {len(mappings_df):,} mapping entries")
       111 -
       112 -      # Load RAW call types
       113 -      print(f"\nLoading RAW call types from: {RAW_CALLTYPES_FILE}")
       114 -      raw_calltypes_df = pd.read_excel(RAW_CALLTYPES_FILE)
       115 -      print(f"  Loaded {len(raw_calltypes_df):,} raw call type entries")
       116 -      print(f"  Columns: {list(raw_calltypes_df.columns)}")
       117 -
       118 -      return cad_df, dv_df, rms_df, mappings_df, raw_calltypes_df
       119 -
       120 -
       121 -  def build_response_type_mapping(mappings_df, raw_calltypes_df):
       122 -      """Build comprehensive Response_Type mapping dictionary.""" 123 -      print("\n" + "=" * 60)
       124 -      print("BUILDING RESPONSE_TYPE MAPPING")
       125 -      print("=" * 60)
       126 -
       127 -      response_map = {}
       128 -
       129 -      # First, build mapping from RAW call types
       130 -      # Check for Response_Type or Response column
       131 -      response_col = None
       132 -      for col in ['Response_Type', 'Response', 'ResponseType']:
       133 -          if col in raw_calltypes_df.columns:
       134 -              response_col = col
       135 -              break
       136 -
       137 -      calltype_col = None
       138 -      for col in ['Call_Type', 'CallType', 'Incident', 'Call Type']:
       139 -          if col in raw_calltypes_df.columns:
       140 -              calltype_col = col
       141 -              break
       142 -
       143 -      if response_col and calltype_col:
       144 -          for _, row in raw_calltypes_df.iterrows():
       145 -              call_type = fix_mojibake(str(row[calltype_col]).strip())
       146 -              response = row[response_col]
       147 -              if pd.notna(response) and str(response).strip():
       148 -                  response_map[call_type] = str(response).strip()
       149 -          print(f"  Loaded {len(response_map)} mappings from RAW call types")
       150 -
       151 -      # Add manual mappings (these override RAW mappings)
       152 -      manual_count = 0
       153 -      for _, row in mappings_df.iterrows():
       154 -          unmapped = fix_mojibake(str(row.get('Unmapped_Call_Type', '')).strip())
       155 -          raw_type = fix_mojibake(str(row.get('Raw_Call_Type', '')).strip())
       156 -          response = str(row.get('Response', '')).strip()
       157 -
       158 -          if unmapped and response:
       159 -              response_map[unmapped] = response
       160 -              manual_count += 1
       161 -          if raw_type and response:
       162 -              response_map[raw_type] = response
       163 -              manual_count += 1
       164 -
       165 -      print(f"  Added {manual_count} manual mappings")
       166 -      print(f"  Total mapping entries: {len(response_map)}")
       167 -
       168 -      return response_map
       169 -
       170 -
       171 -  def apply_response_type_mapping(cad_df, response_map):
       172 -      """Apply Response_Type mappings to CAD data.""" 173 -      print("\n" + "=" * 60)
       174 -      print("APPLYING RESPONSE_TYPE MAPPINGS")
       175 -      print("=" * 60)
       176 -
       177 -      # Backup original values
       178 -      if 'Response_Type' in cad_df.columns:
       179 -          cad_df['Response_Type_Original'] = cad_df['Response_Type'].copy()
       180 -      else:
       181 -          cad_df['Response_Type'] = ''
       182 -          cad_df['Response_Type_Original'] = ''
       183 -
       184 -      # Fix mojibake in Incident column
       185 -      cad_df['Incident'] = cad_df['Incident'].apply(fix_mojibake)
       186 -
       187 -      mapped_count = 0
       188 -      unmapped_incidents = set()
       189 -
       190 -      for idx, row in cad_df.iterrows():
       191 -          incident = str(row['Incident']).strip()
       192 -          current_response = row.get('Response_Type', '')
       193 -
       194 -          # Only map if Response_Type is empty or NaN
       195 -          if pd.isna(current_response) or str(current_response).strip() == '':
       196 -              if incident in response_map:
       197 -                  cad_df.at[idx, 'Response_Type'] = response_map[incident]
       198 -                  mapped_count += 1
       199 -                  metrics['changes'].append({
       200 -                      'index': idx,
       201 -                      'field': 'Response_Type',
       202 -                      'old_value': '',
       203 -                      'new_value': response_map[incident],
       204 -                      'reason': 'Manual mapping applied'
       205 -                  })
       206 -              else:
       207 -                  unmapped_incidents.add(incident)
       208 -
       209 -      metrics['response_type_mapped'] = mapped_count
       210 -      metrics['response_type_unmapped'] = len(unmapped_incidents)
       211 -
       212 -      # Calculate coverage
       213 -      total = len(cad_df)
       214 -      with_response = cad_df['Response_Type'].notna() & (cad_df['Response_Type'] != '')
       215 -      coverage = (with_response.sum() / total) * 100
       216 -
       217 -      print(f"  Mapped {mapped_count:,} records")
       218 -      print(f"  Unmapped incident types: {len(unmapped_incidents)}")
       219 -      print(f"  Current Response_Type coverage: {coverage:.2f}%")
       220 -
       221 -      if unmapped_incidents:
       222 -          print(f"\n  Sample unmapped incidents:")
       223 -          for i, inc in enumerate(list(unmapped_incidents)[:10]):
       224 -              print(f"    - {inc}")
       225 -
       226 -      return cad_df
       227 -
       228 -
       229 -  def resolve_taps_variants(cad_df):
       230 -      """Resolve TAPS variant mappings (Blocker #8).""" 231 -      print("\n" + "=" * 60)
       232 -      print("RESOLVING TAPS VARIANTS (Blocker #8)")
       233 -      print("=" * 60)
       234 -
       235 -      # TAPS variant mappings
       236 -      taps_mappings = {
       237 -          'Targeted Area Patrol': {
       238 -              'default': 'TAPS - Other',
       239 -              'keywords': {
       240 -                  'business': 'TAPS - Business',
       241 -                  'housing': 'TAPS - Housing',
       242 -                  'medical': 'TAPS - Medical Facility',
       243 -                  'hospital': 'TAPS - Medical Facility',
       244 -                  'park': 'TAPS - Park',
       245 -                  'garage': 'TAPS - Parking Garage',
       246 -                  'parking': 'TAPS - Parking Garage',
       247 -                  'church': 'TAPS - Religious Facility',
       248 -                  'mosque': 'TAPS - Religious Facility',
       249 -                  'synagogue': 'TAPS - Religious Facility',
       250 -                  'temple': 'TAPS - Religious Facility',
       251 -                  'religious': 'TAPS - Religious Facility',
       252 -                  'school': 'TAPS - School'
       253 -              }
       254 -          },
       255 -          'ESU - Targeted Patrol': {
       256 -              'default': 'TAPS - ESU - Other',
       257 -              'keywords': {
       258 -                  'business': 'TAPS - ESU - Business',
       259 -                  'medical': 'TAPS - ESU - Medical Facility',
       260 -                  'hospital': 'TAPS - ESU - Medical Facility',
       261 -                  'park': 'TAPS - ESU - Park',
       262 -                  'garage': 'TAPS - ESU - Parking Garage',
       263 -                  'parking': 'TAPS - ESU - Parking Garage',
       264 -                  'church': 'TAPS - ESU - Religious Facility',
       265 -                  'mosque': 'TAPS - ESU - Religious Facility',
       266 -                  'synagogue': 'TAPS - ESU - Religious Facility',
       267 -                  'temple': 'TAPS - ESU - Religious Facility',
       268 -                  'religious': 'TAPS - ESU - Religious Facility',
       269 -                  'school': 'TAPS - ESU - School'
       270 -              }
       271 -          }
       272 -      }
       273 -
       274 -      resolved_count = 0
       275 -
       276 -      for idx, row in cad_df.iterrows():
       277 -          incident = str(row['Incident']).strip()
       278 -
       279 -          if incident in taps_mappings:
       280 -              mapping_info = taps_mappings[incident]
       281 -              new_incident = mapping_info['default']
       282 -
       283 -              # Try to determine specific type from address
       284 -              address = str(row.get('FullAddress2', '')).lower()
       285 -
       286 -              for keyword, specific_type in mapping_info['keywords'].items():
       287 -                  if keyword in address:
       288 -                      new_incident = specific_type
       289 -                      break
       290 -
       291 -              # Update the incident
       292 -              cad_df.at[idx, 'Incident'] = new_incident
       293 -              cad_df.at[idx, 'Response_Type'] = 'Routine'
       294 -              resolved_count += 1
       295 -
       296 -              metrics['changes'].append({
       297 -                  'index': idx,
       298 -                  'field': 'Incident',
       299 -                  'old_value': incident,
       300 -                  'new_value': new_incident,
       301 -                  'reason': 'TAPS variant resolution'
       302 -              })
       303 -
       304 -      metrics['taps_resolved'] = resolved_count
       305 -      print(f"  Resolved {resolved_count:,} TAPS variant records")
       306 -
       307 -      return cad_df
       308 -
       309 -
       310 -  def classify_domestic_disputes(cad_df, dv_df):
       311 -      """Classify Domestic Disputes based on DV report (Blocker #9).""" 312 -      print("\n" + "=" * 60)
       313 -      print("CLASSIFYING DOMESTIC DISPUTES (Blocker #9)")
       314 -      print("=" * 60)
       315 -
       316 -      # Get set of DV case numbers
       317 -      dv_cases = set()
       318 -      case_col = 'Case_Number'
       319 -      if case_col in dv_df.columns:
       320 -          dv_cases = set(dv_df[case_col].dropna().astype(str).str.strip())
       321 -
       322 -      print(f"  DV report contains {len(dv_cases):,} case numbers")
       323 -
       324 -      dv_count = 0
       325 -      dispute_count = 0
       326 -
       327 -      for idx, row in cad_df.iterrows():
       328 -          incident = str(row['Incident']).strip()
       329 -
       330 -          if incident == 'Domestic Dispute':
       331 -              report_num = str(row.get('ReportNumberNew', '')).strip()
       332 -
       333 -              if report_num in dv_cases:
       334 -                  # Has DV report - classify as Domestic Violence
       335 -                  cad_df.at[idx, 'Incident'] = 'Domestic Violence - 2C:25-21'
       336 -                  cad_df.at[idx, 'Response_Type'] = 'Emergency'
       337 -                  dv_count += 1
       338 -
       339 -                  metrics['changes'].append({
       340 -                      'index': idx,
       341 -                      'field': 'Incident',
       342 -                      'old_value': 'Domestic Dispute',
       343 -                      'new_value': 'Domestic Violence - 2C:25-21',
       344 -                      'reason': 'Has DV report'
       345 -                  })
       346 -              else:
       347 -                  # No DV report - classify as Dispute
       348 -                  cad_df.at[idx, 'Incident'] = 'Dispute'
       349 -                  cad_df.at[idx, 'Response_Type'] = 'Urgent'
       350 -                  dispute_count += 1
       351 -
       352 -                  metrics['changes'].append({
       353 -                      'index': idx,
       354 -                      'field': 'Incident',
       355 -                      'old_value': 'Domestic Dispute',
       356 -                      'new_value': 'Dispute',
       357 -                      'reason': 'No DV report found'
       358 -                  })
       359 -
       360 -      metrics['domestic_to_dv'] = dv_count
       361 -      metrics['domestic_to_dispute'] = dispute_count
       362 -
       363 -      print(f"  Reclassified to Domestic Violence: {dv_count:,}")
       364 -      print(f"  Reclassified to Dispute: {dispute_count:,}")
       365 -
       366 -      return cad_df
       367 -
       368 -
       369 -  def split_tro_fro(cad_df, rms_df):
       370 -      """Split TRO/FRO violations based on RMS narrative (Blocker #10).""" 371 -      print("\n" + "=" * 60)
       372 -      print("SPLITTING TRO/FRO VIOLATIONS (Blocker #10)")
       373 -      print("=" * 60)
       374 -
       375 -      # Build RMS lookup by case number
       376 -      rms_lookup = {}
       377 -      case_col = None
       378 -      for col in ['Case Number', 'CaseNumber', 'Case_Number']:
       379 -          if col in rms_df.columns:
       380 -              case_col = col
       381 -              break
       382 -
       383 -      narrative_col = None
       384 -      for col in ['Narrative', 'narrative', 'NARRATIVE', 'Description']:
       385 -          if col in rms_df.columns:
       386 -              narrative_col = col
       387 -              break
       388 -
       389 -      if case_col and narrative_col:
       390 -          for _, row in rms_df.iterrows():
       391 -              case_num = str(row[case_col]).strip()
       392 -              narrative = str(row.get(narrative_col, '')).lower()
       393 -              rms_lookup[case_num] = narrative
       394 -
       395 -      print(f"  Built RMS lookup with {len(rms_lookup):,} entries")
       396 -
       397 -      split_count = 0
       398 -      manual_review = []
       399 -
       400 -      target_incident = 'Violation: TRO/ FRO  2C:25-31'
       401 -      # Also check for variations
       402 -      target_variations = [
       403 -          'Violation: TRO/ FRO  2C:25-31',
       404 -          'Violation: TRO/FRO 2C:25-31',
       405 -          'Violation TRO/FRO - 2C:25-31'
       406 -      ]
       407 -
       408 -      for idx, row in cad_df.iterrows():
       409 -          incident = str(row['Incident']).strip()
       410 -
       411 -          if incident in target_variations or 'TRO' in incident and 'FRO' in incident and 'Violation'
           -  in incident:
       412 -              report_num = str(row.get('ReportNumberNew', '')).strip()
       413 -              narrative = rms_lookup.get(report_num, '')
       414 -
       415 -              new_incident = None
       416 -
       417 -              # Check for FRO indicators
       418 -              if 'fro' in narrative or 'final' in narrative or 'final restraining' in narrative:
       419 -                  new_incident = 'Violation FRO - 2C:29-9b'
       420 -              # Check for TRO indicators
       421 -              elif 'tro' in narrative or 'temporary' in narrative or 'temporary restraining' in
           - narrative:
       422 -                  new_incident = 'Violation TRO - 2C:29-9b'
       423 -
       424 -              if new_incident:
       425 -                  cad_df.at[idx, 'Incident'] = new_incident
       426 -                  cad_df.at[idx, 'Response_Type'] = 'Routine'
       427 -                  split_count += 1
       428 -
       429 -                  metrics['changes'].append({
       430 -                      'index': idx,
       431 -                      'field': 'Incident',
       432 -                      'old_value': incident,
       433 -                      'new_value': new_incident,
       434 -                      'reason': 'TRO/FRO split based on narrative'
       435 -                  })
       436 -              else:
       437 -                  # No match - log for manual review
       438 -                  manual_review.append({
       439 -                      'index': idx,
       440 -                      'ReportNumberNew': report_num,
       441 -                      'original_incident': incident
       442 -                  })
       443 -
       444 -      metrics['tro_fro_split'] = split_count
       445 -      metrics['tro_fro_manual_review'] = len(manual_review)
       446 -
       447 -      print(f"  Split {split_count:,} TRO/FRO records")
       448 -      print(f"  Records for manual review: {len(manual_review):,}")
       449 -
       450 -      # Save manual review list
       451 -      if manual_review:
       452 -          review_df = pd.DataFrame(manual_review)
       453 -          review_file = REPORTS_DIR / "tro_fro_manual_review.csv"
       454 -          review_df.to_csv(review_file, index=False)
       455 -          print(f"  Manual review list saved to: {review_file}")
       456 -
       457 -      return cad_df
       458 -
       459 -
       460 -  def normalize_disposition(cad_df):
       461 -      """Normalize Disposition values to title case with specific mappings.""" 462 -      print("\n" + "=" * 60)
       463 -      print("NORMALIZING DISPOSITION VALUES")
       464 -      print("=" * 60)
       465 -
       466 -      # Specific disposition mappings
       467 -      disposition_map = {
       468 -          'ASSISTED': 'Assisted',
       469 -          'CANCELED': 'Cancelled',
       470 -          'CANCELLED': 'Cancelled',
       471 -          'CHECKED OK': 'Checked OK',
       472 -          'CHECKED O.K. ': 'Checked OK',
       473 -          'UNFOUNDED': 'Unfounded',
       474 -          'REPORT TAKEN': 'Report Taken',
       475 -          'ARREST': 'Arrest',
       476 -          'CITATION': 'Citation',
       477 -          'GONE ON ARRIVAL': 'Gone on Arrival',
       478 -          'GOA': 'Gone on Arrival',
       479 -          'UNABLE TO LOCATE': 'Unable to Locate',
       480 -          'UTL': 'Unable to Locate',
       481 -          'WARNING': 'Warning',
       482 -          'REFERRED': 'Referred',
       483 -          'DUPLICATE': 'Duplicate',
       484 -          'NO ACTION REQUIRED': 'No Action Required',
       485 -          'TRANSPORTED': 'Transported'
       486 -      }
       487 -
       488 -      normalized_count = 0
       489 -
       490 -      if 'Disposition' in cad_df.columns:
       491 -          cad_df['Disposition_Original'] = cad_df['Disposition'].copy()
       492 -
       493 -          for idx, row in cad_df.iterrows():
       494 -              disp = row['Disposition']
       495 -              if pd.notna(disp):
       496 -                  disp_str = str(disp).strip().upper()
       497 -
       498 -                  if disp_str in disposition_map:
       499 -                      new_disp = disposition_map[disp_str]
       500 -                  else:
       501 -                      # Apply title case for unmapped values
       502 -                      new_disp = str(disp).strip().title()
       503 -
       504 -                  if str(disp).strip() != new_disp:
       505 -                      cad_df.at[idx, 'Disposition'] = new_disp
       506 -                      normalized_count += 1
       507 -
       508 -                      metrics['changes'].append({
       509 -                          'index': idx,
       510 -                          'field': 'Disposition',
       511 -                          'old_value': str(disp).strip(),
       512 -                          'new_value': new_disp,
       513 -                          'reason': 'Disposition normalization'
       514 -                      })
       515 -
       516 -      metrics['disposition_normalized'] = normalized_count
       517 -      print(f"  Normalized {normalized_count:,} disposition values")
       518 -
       519 -      return cad_df
       520 -
       521 -
       522 -  def backfill_address_from_rms(cad_df, rms_df):
       523 -      """Backfill invalid FullAddress2 values from RMS data.""" 524 -      print("\n" + "=" * 60)
       525 -      print("BACKFILLING ADDRESSES FROM RMS")
       526 -      print("=" * 60)
       527 -
       528 -      # Identify invalid addresses
       529 -      invalid_patterns = [
       530 -          r'^\d+$',  # Just numbers
       531 -          r'^[A-Z]+$',  # Just letters (all caps)
       532 -          r'^unknown',
       533 -          r'^n/a',
       534 -          r'^none',
       535 -          r'^\s*$',  # Empty or whitespace
       536 -      ]
       537 -
       538 -      def is_invalid_address(addr):
       539 -          if pd.isna(addr):
       540 -              return True
       541 -          addr_str = str(addr).strip().lower()
       542 -          if not addr_str:
       543 -              return True
       544 -          # Check if has street number
       545 -          if not re.search(r'\d+\s+\w+', str(addr)):
       546 -              return True
       547 -          for pattern in invalid_patterns:
       548 -              if re.match(pattern, addr_str, re.IGNORECASE):
       549 -                  return True
       550 -          return False
       551 -
       552 -      # Build RMS address lookup
       553 -      rms_lookup = {}
       554 -      case_col = None
       555 -      for col in ['Case Number', 'CaseNumber', 'Case_Number']:
       556 -          if col in rms_df.columns:
       557 -              case_col = col
       558 -              break
       559 -
       560 -      address_col = None
       561 -      for col in ['FullAddress', 'Address', 'Location', 'Full Address']:
       562 -          if col in rms_df.columns:
       563 -              address_col = col
       564 -              break
       565 -
       566 -      officer_col = None
       567 -      for col in ['Officer of Record', 'Officer', 'OfficerOfRecord']:
       568 -          if col in rms_df.columns:
       569 -              officer_col = col
       570 -              break
       571 -
       572 -      if case_col and address_col:
       573 -          for _, row in rms_df.iterrows():
       574 -              case_num = str(row[case_col]).strip()
       575 -              address = str(row.get(address_col, '')).strip()
       576 -              officer = str(row.get(officer_col, '')).strip() if officer_col else ''
       577 -
       578 -              if address and not is_invalid_address(address):
       579 -                  rms_lookup[case_num] = {'address': address, 'officer': officer}
       580 -
       581 -      print(f"  Built RMS address lookup with {len(rms_lookup):,} valid addresses")
       582 -
       583 -      # Backup original addresses
       584 -      cad_df['FullAddress2_Original'] = cad_df['FullAddress2'].copy()
       585 -
       586 -      backfill_count = 0
       587 -
       588 -      for idx, row in cad_df.iterrows():
       589 -          if is_invalid_address(row.get('FullAddress2')):
       590 -              report_num = str(row.get('ReportNumberNew', '')).strip()
       591 -
       592 -              if report_num in rms_lookup:
       593 -                  rms_data = rms_lookup[report_num]
       594 -
       595 -                  # Optional: cross-check officer
       596 -                  cad_officer = str(row.get('Officer', '')).lower()
       597 -                  rms_officer = rms_data['officer'].lower()
       598 -
       599 -                  # Apply backfill (with or without officer match)
       600 -                  cad_df.at[idx, 'FullAddress2'] = rms_data['address']
       601 -                  backfill_count += 1
       602 -
       603 -                  metrics['changes'].append({
       604 -                      'index': idx,
       605 -                      'field': 'FullAddress2',
       606 -                      'old_value': str(row.get('FullAddress2', '')),
       607 -                      'new_value': rms_data['address'],
       608 -                      'reason': 'Address backfilled from RMS'
       609 -                  })
       610 -
       611 -      metrics['address_backfilled'] = backfill_count
       612 -      print(f"  Backfilled {backfill_count:,} addresses from RMS")
       613 -
       614 -      return cad_df
       615 -
       616 -
       617 -  def add_data_quality_flags(cad_df):
       618 -      """Add data quality flags to identify records needing review."""